# -*- coding: utf-8 -*-
"""IC1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hqwplt2nMpVmmhdLxlRogFtnaggvDYdG
"""

!curl -s https://course.fast.ai/setup/colab | bash

from fastai import *
from fastai.vision import *
import numpy as np

from google.colab import drive
drive.mount('/content/gdrive')

import tensorflow as tf

DATASET_PATH ='/content/gdrive/My Drive/Covid19Pics/Covid_Data_GradientCrescent/all/train' #'D:\\ProjectCovid19\\Covid_Data_GradientCrescent\\two\\train'
test_dir = '/content/gdrive/My Drive/Covid19Pics/Covid_Data_GradientCrescent/all/test'#'D:\\ProjectCovid19\\Covid_Data_GradientCrescent\\two\\test'

IMAGE_SIZE = (150,150)
BATCH_SIZE = 10
NUM_EPOCHS = 100
LEARNING_RATE =1E-4



from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255,
 rotation_range=50,
 featurewise_center = True,
 featurewise_std_normalization = True,
 width_shift_range=0.2,
 height_shift_range=0.2,
 shear_range=0.25,
 zoom_range=0.1,
 zca_whitening = True,
 channel_shift_range = 20,
 horizontal_flip = True ,
 vertical_flip = True ,
 validation_split = 0.2,
 fill_mode='constant')

train_batches = train_datagen.flow_from_directory(DATASET_PATH,
 target_size=IMAGE_SIZE,
 shuffle=True,
 batch_size=BATCH_SIZE,
 subset = "training",
 seed=42,
 class_mode="categorical",
 )

valid_batches = train_datagen.flow_from_directory(DATASET_PATH,
 target_size=IMAGE_SIZE,
 shuffle=True,
 batch_size=BATCH_SIZE,
 subset = "validation",
 seed=42,
 class_mode="categorical",
 )

from keras import models
from keras import layers
from keras.applications import VGG16
from keras import optimizers
from keras.layers.core import Flatten, Dense, Dropout, Lambda
from keras.backend import sigmoid
def swish(x, beta = 1):
  return (x * sigmoid(beta * x))
from tensorflow.keras.layers import BatchNormalization

from keras.utils.generic_utils import get_custom_objects
from keras.layers import Activation
get_custom_objects().update({'swish': Activation(swish)})

conv_base = VGG16(weights='imagenet',
 include_top=False,
 input_shape=(150,150, 3))
conv_base.trainable = False


model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='swish'))
model.add(layers.Dense(1024, activation='swish'))
model.add(layers.Dense(256, activation='swish'))
model.add(layers.Dense(4, activation="softmax"))

model.compile(loss='categorical_crossentropy',
 
 optimizer=optimizers.Adam(lr=LEARNING_RATE),
 metrics=['accuracy'])

STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size
STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size
history=model.fit_generator(train_batches,
 steps_per_epoch =STEP_SIZE_TRAIN,
 validation_data = valid_batches,
 validation_steps = STEP_SIZE_VALID,
 epochs= NUM_EPOCHS,
 )

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from google.colab import drive
drive.mount('/content/drive')

test_datagen = ImageDataGenerator(rescale=1. / 255)
eval_generator = test_datagen.flow_from_directory(
 test_dir,target_size=IMAGE_SIZE,
 batch_size=1,
 shuffle=False,
 seed=42,
 class_mode="categorical")

eval_generator.reset()
x = model.evaluate_generator(eval_generator,
 steps = np.ceil(len(eval_generator) / BATCH_SIZE),
 use_multiprocessing = False,
 verbose = 1,
 workers=1
 )
print('Test loss:' , x[0])
print('Test accuracy:',x[1])